---
title: Exploiting Performance-based Similarity between Datasets in Metalearning
abstract: This paper describes an improved algorithm selection method of a previous
  method called active testing. This method seeks a workflow (or its particular configuration)
  that would lead to the highest gain in performance (e.g., accuracy). The new version
  uses a particular performance-based characterization of each dataset, which is in
  the form of a vector of performance values of different algorithms. Dataset similarity
  is then assessed by comparing these performance vectors. One useful measure for
  this comparison is Spearmanâ€™s correlation. The advantage of this measure is that
  it can be easily recalculated as more information is gathered. Consequently, as
  the tests proceed, the recommendations of the system get adjusted to the characteristics
  of the target dataset. We show that this new strategy leads to improved results
  of the active testing approach.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: leite21a
month: 0
tex_title: Exploiting Performance-based Similarity between Datasets in Metalearning
firstpage: 90
lastpage: 99
page: 90-99
order: 90
cycles: false
bibtex_author: Leite, Rui and Brazdil, Pavel
author:
- given: Rui
  family: Leite
- given: Pavel
  family: Brazdil
date: 2021-08-18
address:
container-title: AAAI Workshop on Meta-Learning and MetaDL Challenge
volume: '140'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 8
  - 18
pdf: http://proceedings.mlr.press/v140/leite21a/leite21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
